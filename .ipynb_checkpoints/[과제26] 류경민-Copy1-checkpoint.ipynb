{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = pd.read_csv('./dataset/wine.csv', header=None)\n",
    "data = data_pre.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1     2    3      4     5      6        7     8     9     10  \\\n",
      "2259  7.1  0.280  0.26  1.9  0.049  12.0   86.0  0.99340  3.15  0.38   9.4   \n",
      "4818  6.2  0.350  0.31  2.6  0.036  37.0   92.0  0.98938  3.27  0.53  12.8   \n",
      "5166  6.9  0.260  0.27  4.2  0.031  20.0   80.0  0.99089  3.12  0.39  11.5   \n",
      "3227  8.2  0.200  0.49  3.5  0.057  14.0  108.0  0.99280  3.19  0.35  11.5   \n",
      "349   9.1  0.785  0.00  2.6  0.093  11.0   28.0  0.99940  3.36  0.86   9.4   \n",
      "\n",
      "      11  12  \n",
      "2259   5   0  \n",
      "4818   7   0  \n",
      "5166   6   0  \n",
      "3227   6   0  \n",
      "349    6   1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values\n",
    "X = dataset[:,0:11]\n",
    "Y = dataset[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "Y_Hot = tf.one_hot(Y,depth=8).eval(session = sess)\n",
    "Y_Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=11, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8466 - acc: 0.4365\n",
      "Epoch 2/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8456 - acc: 0.4365\n",
      "Epoch 3/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8455 - acc: 0.4365\n",
      "Epoch 4/500\n",
      "6497/6497 [==============================] - 0s 12us/step - loss: 5.8446 - acc: 0.4365\n",
      "Epoch 5/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8454 - acc: 0.4365\n",
      "Epoch 6/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8516 - acc: 0.4365\n",
      "Epoch 7/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8484 - acc: 0.4365\n",
      "Epoch 8/500\n",
      "6497/6497 [==============================] - 0s 12us/step - loss: 5.8463 - acc: 0.4365\n",
      "Epoch 9/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8450 - acc: 0.4365\n",
      "Epoch 10/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8457 - acc: 0.4365\n",
      "Epoch 11/500\n",
      "6497/6497 [==============================] - 0s 12us/step - loss: 5.8442 - acc: 0.4365\n",
      "Epoch 12/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8431 - acc: 0.4365\n",
      "Epoch 13/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8432 - acc: 0.4365\n",
      "Epoch 14/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8423 - acc: 0.4365\n",
      "Epoch 15/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8426 - acc: 0.4365: 0s - loss: 5.8601 - acc: 0.445\n",
      "Epoch 16/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8424 - acc: 0.4365\n",
      "Epoch 17/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8412 - acc: 0.4365\n",
      "Epoch 18/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8416 - acc: 0.4365\n",
      "Epoch 19/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8407 - acc: 0.4365\n",
      "Epoch 20/500\n",
      "6497/6497 [==============================] - 0s 12us/step - loss: 5.8420 - acc: 0.4365\n",
      "Epoch 21/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8401 - acc: 0.4365\n",
      "Epoch 22/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8401 - acc: 0.4365\n",
      "Epoch 23/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8399 - acc: 0.4362\n",
      "Epoch 24/500\n",
      "6497/6497 [==============================] - 0s 12us/step - loss: 5.8391 - acc: 0.4364\n",
      "Epoch 25/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8386 - acc: 0.4364\n",
      "Epoch 26/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8380 - acc: 0.4364\n",
      "Epoch 27/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8428 - acc: 0.4365\n",
      "Epoch 28/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8398 - acc: 0.4360\n",
      "Epoch 29/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8436 - acc: 0.4362\n",
      "Epoch 30/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8410 - acc: 0.4362\n",
      "Epoch 31/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8375 - acc: 0.4364: 0s - loss: 5.6918 - acc: 0.435\n",
      "Epoch 32/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8365 - acc: 0.4360\n",
      "Epoch 33/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8371 - acc: 0.4362\n",
      "Epoch 34/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8467 - acc: 0.4360\n",
      "Epoch 35/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8368 - acc: 0.4360\n",
      "Epoch 36/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8491 - acc: 0.4357\n",
      "Epoch 37/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8412 - acc: 0.4364\n",
      "Epoch 38/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8378 - acc: 0.4356\n",
      "Epoch 39/500\n",
      "6497/6497 [==============================] - 1s 120us/step - loss: 5.8365 - acc: 0.4364\n",
      "Epoch 40/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8385 - acc: 0.4354\n",
      "Epoch 41/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8353 - acc: 0.4368\n",
      "Epoch 42/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8339 - acc: 0.4364\n",
      "Epoch 43/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8357 - acc: 0.4362\n",
      "Epoch 44/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8364 - acc: 0.4367\n",
      "Epoch 45/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8348 - acc: 0.4368\n",
      "Epoch 46/500\n",
      "6497/6497 [==============================] - 0s 19us/step - loss: 5.8330 - acc: 0.4370\n",
      "Epoch 47/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8312 - acc: 0.4371\n",
      "Epoch 48/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8333 - acc: 0.4368\n",
      "Epoch 49/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8304 - acc: 0.4371\n",
      "Epoch 50/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8304 - acc: 0.4370\n",
      "Epoch 51/500\n",
      "6497/6497 [==============================] - 0s 17us/step - loss: 5.8369 - acc: 0.4365\n",
      "Epoch 52/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8396 - acc: 0.4373\n",
      "Epoch 53/500\n",
      "6497/6497 [==============================] - 0s 19us/step - loss: 5.8350 - acc: 0.4368\n",
      "Epoch 54/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8282 - acc: 0.4377\n",
      "Epoch 55/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8346 - acc: 0.4374\n",
      "Epoch 56/500\n",
      "6497/6497 [==============================] - 0s 19us/step - loss: 5.8299 - acc: 0.4371\n",
      "Epoch 57/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8300 - acc: 0.4373\n",
      "Epoch 58/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8312 - acc: 0.4370\n",
      "Epoch 59/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8383 - acc: 0.4364\n",
      "Epoch 60/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8275 - acc: 0.4370\n",
      "Epoch 61/500\n",
      "6497/6497 [==============================] - 0s 31us/step - loss: 5.8274 - acc: 0.4373\n",
      "Epoch 62/500\n",
      "6497/6497 [==============================] - 0s 36us/step - loss: 5.8291 - acc: 0.4380\n",
      "Epoch 63/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8607 - acc: 0.4368\n",
      "Epoch 64/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8353 - acc: 0.4373\n",
      "Epoch 65/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8264 - acc: 0.4367\n",
      "Epoch 66/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8272 - acc: 0.4374\n",
      "Epoch 67/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8464 - acc: 0.4367\n",
      "Epoch 68/500\n",
      "6497/6497 [==============================] - 0s 28us/step - loss: 5.8320 - acc: 0.4368\n",
      "Epoch 69/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8255 - acc: 0.4379\n",
      "Epoch 70/500\n",
      "6497/6497 [==============================] - 0s 33us/step - loss: 5.8224 - acc: 0.4371\n",
      "Epoch 71/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8245 - acc: 0.4368\n",
      "Epoch 72/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8249 - acc: 0.4380\n",
      "Epoch 73/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8264 - acc: 0.4380\n",
      "Epoch 74/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8249 - acc: 0.4370\n",
      "Epoch 75/500\n",
      "6497/6497 [==============================] - 0s 28us/step - loss: 5.8257 - acc: 0.4368\n",
      "Epoch 76/500\n",
      "6497/6497 [==============================] - 0s 25us/step - loss: 5.8251 - acc: 0.4373\n",
      "Epoch 77/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8199 - acc: 0.4371\n",
      "Epoch 78/500\n",
      "6497/6497 [==============================] - 0s 28us/step - loss: 5.9176 - acc: 0.4365\n",
      "Epoch 79/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8908 - acc: 0.4374\n",
      "Epoch 80/500\n",
      "6497/6497 [==============================] - 0s 36us/step - loss: 5.8660 - acc: 0.4365\n",
      "Epoch 81/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8513 - acc: 0.4364\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 33us/step - loss: 5.8389 - acc: 0.4362\n",
      "Epoch 83/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8384 - acc: 0.4364\n",
      "Epoch 84/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8345 - acc: 0.4370\n",
      "Epoch 85/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8495 - acc: 0.4373\n",
      "Epoch 86/500\n",
      "6497/6497 [==============================] - 0s 19us/step - loss: 5.8346 - acc: 0.4370\n",
      "Epoch 87/500\n",
      "6497/6497 [==============================] - 0s 17us/step - loss: 5.8301 - acc: 0.4373\n",
      "Epoch 88/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8310 - acc: 0.4374\n",
      "Epoch 89/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8288 - acc: 0.4374\n",
      "Epoch 90/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8281 - acc: 0.4377\n",
      "Epoch 91/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8275 - acc: 0.4373\n",
      "Epoch 92/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8264 - acc: 0.4377\n",
      "Epoch 93/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8288 - acc: 0.4376\n",
      "Epoch 94/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8241 - acc: 0.4379\n",
      "Epoch 95/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8620 - acc: 0.4371\n",
      "Epoch 96/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8409 - acc: 0.4376\n",
      "Epoch 97/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8262 - acc: 0.4374\n",
      "Epoch 98/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8231 - acc: 0.4371\n",
      "Epoch 99/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8214 - acc: 0.4376\n",
      "Epoch 100/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8212 - acc: 0.4385\n",
      "Epoch 101/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8148 - acc: 0.4373\n",
      "Epoch 102/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8187 - acc: 0.4384\n",
      "Epoch 103/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8145 - acc: 0.4385\n",
      "Epoch 104/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.8243 - acc: 0.4390\n",
      "Epoch 105/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8193 - acc: 0.4393\n",
      "Epoch 106/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8124 - acc: 0.4382\n",
      "Epoch 107/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8155 - acc: 0.4384\n",
      "Epoch 108/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.8118 - acc: 0.4382\n",
      "Epoch 109/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8157 - acc: 0.4384\n",
      "Epoch 110/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8315 - acc: 0.4360\n",
      "Epoch 111/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8154 - acc: 0.4376\n",
      "Epoch 112/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8125 - acc: 0.4374\n",
      "Epoch 113/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.9280 - acc: 0.4368\n",
      "Epoch 114/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8602 - acc: 0.4365\n",
      "Epoch 115/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.8183 - acc: 0.4365\n",
      "Epoch 116/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.8105 - acc: 0.4365\n",
      "Epoch 117/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8146 - acc: 0.4364\n",
      "Epoch 118/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8090 - acc: 0.4367\n",
      "Epoch 119/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8098 - acc: 0.4376\n",
      "Epoch 120/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8051 - acc: 0.4379\n",
      "Epoch 121/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8084 - acc: 0.4380\n",
      "Epoch 122/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8035 - acc: 0.4384\n",
      "Epoch 123/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8010 - acc: 0.4379\n",
      "Epoch 124/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.7995 - acc: 0.4377\n",
      "Epoch 125/500\n",
      "6497/6497 [==============================] - 0s 29us/step - loss: 5.8053 - acc: 0.4377\n",
      "Epoch 126/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8068 - acc: 0.4371\n",
      "Epoch 127/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8065 - acc: 0.4370\n",
      "Epoch 128/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8160 - acc: 0.4365\n",
      "Epoch 129/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8063 - acc: 0.4379\n",
      "Epoch 130/500\n",
      "6497/6497 [==============================] - 0s 25us/step - loss: 5.8040 - acc: 0.4377\n",
      "Epoch 131/500\n",
      "6497/6497 [==============================] - 0s 25us/step - loss: 5.8048 - acc: 0.4382\n",
      "Epoch 132/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8022 - acc: 0.4379\n",
      "Epoch 133/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.8047 - acc: 0.4370\n",
      "Epoch 134/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8033 - acc: 0.4371\n",
      "Epoch 135/500\n",
      "6497/6497 [==============================] - 0s 25us/step - loss: 5.7999 - acc: 0.4371\n",
      "Epoch 136/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.7988 - acc: 0.4373\n",
      "Epoch 137/500\n",
      "6497/6497 [==============================] - 0s 30us/step - loss: 5.7986 - acc: 0.4371\n",
      "Epoch 138/500\n",
      "6497/6497 [==============================] - 0s 25us/step - loss: 5.7966 - acc: 0.4373\n",
      "Epoch 139/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.7965 - acc: 0.4374\n",
      "Epoch 140/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.7936 - acc: 0.4370\n",
      "Epoch 141/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.7929 - acc: 0.4373\n",
      "Epoch 142/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8522 - acc: 0.4377\n",
      "Epoch 143/500\n",
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8189 - acc: 0.4371\n",
      "Epoch 144/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8102 - acc: 0.4373\n",
      "Epoch 145/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8032 - acc: 0.4370\n",
      "Epoch 146/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.7986 - acc: 0.4380\n",
      "Epoch 147/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.7960 - acc: 0.4371\n",
      "Epoch 148/500\n",
      "6497/6497 [==============================] - 0s 28us/step - loss: 5.7942 - acc: 0.4374\n",
      "Epoch 149/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.7987 - acc: 0.4379\n",
      "Epoch 150/500\n",
      "6497/6497 [==============================] - 1s 135us/step - loss: 5.8781 - acc: 0.4385\n",
      "Epoch 151/500\n",
      "6497/6497 [==============================] - 0s 26us/step - loss: 5.8499 - acc: 0.4388\n",
      "Epoch 152/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8333 - acc: 0.4376\n",
      "Epoch 153/500\n",
      "6497/6497 [==============================] - 0s 24us/step - loss: 5.8274 - acc: 0.4370\n",
      "Epoch 154/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8219 - acc: 0.4371\n",
      "Epoch 155/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8194 - acc: 0.4367\n",
      "Epoch 156/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8157 - acc: 0.4368\n",
      "Epoch 157/500\n",
      "6497/6497 [==============================] - 0s 23us/step - loss: 5.8142 - acc: 0.4384\n",
      "Epoch 158/500\n",
      "6497/6497 [==============================] - 0s 29us/step - loss: 5.8053 - acc: 0.4380\n",
      "Epoch 159/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.8082 - acc: 0.4367\n",
      "Epoch 160/500\n",
      "6497/6497 [==============================] - 0s 29us/step - loss: 5.7943 - acc: 0.4370\n",
      "Epoch 161/500\n",
      "6497/6497 [==============================] - 0s 22us/step - loss: 5.7960 - acc: 0.4382\n",
      "Epoch 162/500\n",
      "6497/6497 [==============================] - 0s 29us/step - loss: 5.7955 - acc: 0.4380\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 [==============================] - 0s 21us/step - loss: 5.8167 - acc: 0.4371\n",
      "Epoch 164/500\n",
      "6497/6497 [==============================] - 0s 19us/step - loss: 5.8409 - acc: 0.4371\n",
      "Epoch 165/500\n",
      "6497/6497 [==============================] - 0s 20us/step - loss: 5.8179 - acc: 0.4365\n",
      "Epoch 166/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.8090 - acc: 0.4365\n",
      "Epoch 167/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.8006 - acc: 0.4365\n",
      "Epoch 168/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7974 - acc: 0.4365\n",
      "Epoch 169/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7998 - acc: 0.4365\n",
      "Epoch 170/500\n",
      "6497/6497 [==============================] - 0s 13us/step - loss: 5.7966 - acc: 0.4367\n",
      "Epoch 171/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7984 - acc: 0.4365\n",
      "Epoch 172/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7956 - acc: 0.4365\n",
      "Epoch 173/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7989 - acc: 0.4365\n",
      "Epoch 174/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.7966 - acc: 0.4365\n",
      "Epoch 175/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7956 - acc: 0.4367\n",
      "Epoch 176/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7949 - acc: 0.4365\n",
      "Epoch 177/500\n",
      "6497/6497 [==============================] - 0s 18us/step - loss: 5.7953 - acc: 0.4367\n",
      "Epoch 178/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.7930 - acc: 0.4367\n",
      "Epoch 179/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7940 - acc: 0.4368\n",
      "Epoch 180/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.7924 - acc: 0.4367\n",
      "Epoch 181/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.7934 - acc: 0.4367\n",
      "Epoch 182/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.7956 - acc: 0.4368\n",
      "Epoch 183/500\n",
      "6497/6497 [==============================] - 0s 16us/step - loss: 5.7947 - acc: 0.4368\n",
      "Epoch 184/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7930 - acc: 0.4368\n",
      "Epoch 185/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.7969 - acc: 0.4371\n",
      "Epoch 186/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7943 - acc: 0.4367\n",
      "Epoch 187/500\n",
      "6497/6497 [==============================] - 0s 15us/step - loss: 5.7902 - acc: 0.4365\n",
      "Epoch 188/500\n",
      "6497/6497 [==============================] - 0s 14us/step - loss: 5.7936 - acc: 0.4368\n",
      "Epoch 189/500\n",
      "6497/6497 [==============================] - 0s 17us/step - loss: 5.7918 - acc: 0.4368\n",
      "Epoch 190/500\n",
      " 100/6497 [..............................] - ETA: 0s - loss: 4.8631 - acc: 0.4400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4481540e178a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\[tf]\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, Y_Hot, epochs=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
